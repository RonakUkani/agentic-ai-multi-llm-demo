# Agentic AI Demo (Multiâ€‘LLM) ðŸš€

A modular Python project to demonstrate building and running AI agents with multiple LLM backends. Initially implemented with **Ollama**, this project is designed to expand in the future to include **OpenAI** and other LLM providers. Additionally, the roadmap includes building a **FastAPI** backend to expose these agents as APIs, which can then be consumed by other platforms, such as Android applications.

---

## Project Structure

```
agenticAI-demo/
â”œâ”€â”€ ollama_agent/              # Ollama-based agent implementation
â”‚   â”œâ”€â”€ __pycache__/           # Python cache files
â”‚   â”œâ”€â”€ agent_runner.py        # Main runner for Ollama agent tasks
â”‚   â”œâ”€â”€ config_settings.py     # Configuration for Ollama agent
â”‚   â”œâ”€â”€ llm_setup.py           # Ollama LLM initialization
â”‚   â”œâ”€â”€ main.py                # Entry point for Ollama agent demo
â”‚   â””â”€â”€ tools_setup.py         # Tool definitions and setup
â”‚
â”œâ”€â”€ openai_agent/              # (Planned) OpenAI agent implementation
â”‚   â””â”€â”€ agent_demo.py          # Demo for OpenAI agent (future expansion)
â”‚
â”œâ”€â”€ venv/                      # Local virtual environment (not tracked by Git)
â”‚
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ .gitignore                 # Ignore rules for Git
```

---

## Features

### Current

* **Ollama Agent Demo**

  * Connects to an Ollama model running locally (`localhost:11434`)
  * Uses `llm_setup.py` to initialize and run the model
  * Structured to allow adding tools and configuration easily

### Planned

* **OpenAI Agent Demo**

  * Similar architecture to Ollama agent
  * Will allow switching between LLM providers

* **FastAPI Backend**

  * Expose agent capabilities via REST API
  * Integrate with external applications (e.g., Android apps)

---

## Installation

### 1. Clone the repository

```bash
git clone <your-repo-url>
cd agenticAI-demo
```

### 2. Create and activate a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run Ollama locally

Make sure Ollama is installed and running:

```bash
ollama serve
ollama run <model-name>
```

### 5. Run the Ollama agent

```bash
python ollama_agent/main.py
```

---

## Requirements

Dependencies are listed in `requirements.txt`. Example:

```txt
langchain
requests
python-dotenv
```

---

## Roadmap

* [x] Initial Ollama agent implementation
* [ ] Add OpenAI agent
* [ ] Build FastAPI backend for agents
* [ ] Integrate API with Android application

---

## License

This project is licensed under the MIT License - see the LICENSE file for details.
